{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-06 19:51:12,218] A new study created in memory with name: XGBoost_BreastCancer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inizio Ottimizzazione Bayesiana ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f402b88ff4054d18bb50039316b1f51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-06 19:51:12,974] Trial 0 finished with value: 0.9670329670329669 and parameters: {'n_estimators': 431, 'learning_rate': 0.046126194303366744, 'max_depth': 9, 'subsample': 0.9826452144281044, 'colsample_bytree': 0.5997488722531131, 'reg_alpha': 5.588442879808919e-05, 'reg_lambda': 5.423099576094846}. Best is trial 0 with value: 0.9670329670329669.\n",
      "[I 2026-01-06 19:51:14,660] Trial 1 finished with value: 0.9604395604395604 and parameters: {'n_estimators': 549, 'learning_rate': 0.005540913426134001, 'max_depth': 10, 'subsample': 0.5903986727471358, 'colsample_bytree': 0.9211118105074912, 'reg_alpha': 0.00011764987664583178, 'reg_lambda': 8.430663132589746e-07}. Best is trial 0 with value: 0.9670329670329669.\n",
      "[I 2026-01-06 19:51:15,920] Trial 2 finished with value: 0.956043956043956 and parameters: {'n_estimators': 574, 'learning_rate': 0.0028135694225538636, 'max_depth': 5, 'subsample': 0.5433970779139308, 'colsample_bytree': 0.6711770492473093, 'reg_alpha': 0.000449247489849137, 'reg_lambda': 0.000841594101330925}. Best is trial 0 with value: 0.9670329670329669.\n",
      "[I 2026-01-06 19:51:17,803] Trial 3 finished with value: 0.956043956043956 and parameters: {'n_estimators': 915, 'learning_rate': 0.0011836555619584108, 'max_depth': 7, 'subsample': 0.9677576801829956, 'colsample_bytree': 0.5333507897909944, 'reg_alpha': 0.8951278190344762, 'reg_lambda': 1.151100715482625e-08}. Best is trial 0 with value: 0.9670329670329669.\n",
      "[I 2026-01-06 19:51:18,205] Trial 4 finished with value: 0.9692307692307693 and parameters: {'n_estimators': 587, 'learning_rate': 0.2222344862648336, 'max_depth': 3, 'subsample': 0.7290057087516145, 'colsample_bytree': 0.6672295049211954, 'reg_alpha': 8.690789351735112e-07, 'reg_lambda': 0.000241287035872833}. Best is trial 4 with value: 0.9692307692307693.\n",
      "[I 2026-01-06 19:51:19,452] Trial 5 finished with value: 0.8241758241758241 and parameters: {'n_estimators': 215, 'learning_rate': 0.0010805355078810433, 'max_depth': 10, 'subsample': 0.6023247493531003, 'colsample_bytree': 0.794946758089033, 'reg_alpha': 2.6885348717290413e-08, 'reg_lambda': 2.100877563711005e-08}. Best is trial 4 with value: 0.9692307692307693.\n",
      "[I 2026-01-06 19:51:20,863] Trial 6 finished with value: 0.9670329670329672 and parameters: {'n_estimators': 981, 'learning_rate': 0.011368405306690999, 'max_depth': 6, 'subsample': 0.8106716364066278, 'colsample_bytree': 0.8152608923451636, 'reg_alpha': 0.21260933057161138, 'reg_lambda': 0.00018927257674013285}. Best is trial 4 with value: 0.9692307692307693.\n",
      "[I 2026-01-06 19:51:21,446] Trial 7 finished with value: 0.9736263736263737 and parameters: {'n_estimators': 540, 'learning_rate': 0.07950348593982509, 'max_depth': 9, 'subsample': 0.6321157954474906, 'colsample_bytree': 0.8999576069253096, 'reg_alpha': 0.7445552089597824, 'reg_lambda': 7.680908388285546e-08}. Best is trial 7 with value: 0.9736263736263737.\n",
      "[I 2026-01-06 19:51:22,063] Trial 8 finished with value: 0.9626373626373625 and parameters: {'n_estimators': 689, 'learning_rate': 0.08939971067470927, 'max_depth': 9, 'subsample': 0.9898616497689985, 'colsample_bytree': 0.5637286538383701, 'reg_alpha': 2.8126161752827032, 'reg_lambda': 2.303813582139199}. Best is trial 7 with value: 0.9736263736263737.\n",
      "[I 2026-01-06 19:51:22,437] Trial 9 finished with value: 0.9494505494505494 and parameters: {'n_estimators': 182, 'learning_rate': 0.009646331652663109, 'max_depth': 8, 'subsample': 0.7582114767512848, 'colsample_bytree': 0.5813502393847959, 'reg_alpha': 3.0800947084553183, 'reg_lambda': 0.002621467754625445}. Best is trial 7 with value: 0.9736263736263737.\n",
      "[I 2026-01-06 19:51:22,894] Trial 10 finished with value: 0.9758241758241759 and parameters: {'n_estimators': 358, 'learning_rate': 0.037224182232090355, 'max_depth': 4, 'subsample': 0.6567157538164675, 'colsample_bytree': 0.9481183702285045, 'reg_alpha': 0.006121885127208658, 'reg_lambda': 2.309481327042371e-06}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:23,296] Trial 11 finished with value: 0.9758241758241759 and parameters: {'n_estimators': 346, 'learning_rate': 0.041454778349324845, 'max_depth': 3, 'subsample': 0.674981246835691, 'colsample_bytree': 0.9925271716391023, 'reg_alpha': 0.02007904154196837, 'reg_lambda': 2.002222551886914e-06}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:23,742] Trial 12 finished with value: 0.9736263736263737 and parameters: {'n_estimators': 330, 'learning_rate': 0.024589201108170637, 'max_depth': 3, 'subsample': 0.6905030940812641, 'colsample_bytree': 0.9817637070791428, 'reg_alpha': 0.011755019691188836, 'reg_lambda': 4.741467866767218e-06}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:24,290] Trial 13 finished with value: 0.9670329670329672 and parameters: {'n_estimators': 338, 'learning_rate': 0.028618830641665257, 'max_depth': 4, 'subsample': 0.8341186997702207, 'colsample_bytree': 0.9994341395877836, 'reg_alpha': 0.009209956967220633, 'reg_lambda': 1.0093865848901916e-05}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:24,475] Trial 14 finished with value: 0.9692307692307693 and parameters: {'n_estimators': 121, 'learning_rate': 0.2220632359265291, 'max_depth': 5, 'subsample': 0.673841133642572, 'colsample_bytree': 0.8859845336434575, 'reg_alpha': 0.00756808648175697, 'reg_lambda': 6.364297307934343e-07}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:24,824] Trial 15 finished with value: 0.9714285714285715 and parameters: {'n_estimators': 345, 'learning_rate': 0.08765536472098634, 'max_depth': 4, 'subsample': 0.5320682949321369, 'colsample_bytree': 0.837471063835043, 'reg_alpha': 0.054540862175130704, 'reg_lambda': 0.02790326363738982}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:25,565] Trial 16 finished with value: 0.9670329670329672 and parameters: {'n_estimators': 794, 'learning_rate': 0.048696933108378436, 'max_depth': 4, 'subsample': 0.8649658485027052, 'colsample_bytree': 0.9423972895236382, 'reg_alpha': 0.0008771470095380266, 'reg_lambda': 1.3912783942175281e-05}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:26,194] Trial 17 finished with value: 0.9714285714285715 and parameters: {'n_estimators': 448, 'learning_rate': 0.015300984246879023, 'max_depth': 3, 'subsample': 0.6594098276935717, 'colsample_bytree': 0.7437457630717899, 'reg_alpha': 9.195919455218723e-06, 'reg_lambda': 3.0867753651656224e-07}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:26,852] Trial 18 finished with value: 0.9604395604395604 and parameters: {'n_estimators': 216, 'learning_rate': 0.005036866945088891, 'max_depth': 6, 'subsample': 0.7480428970009217, 'colsample_bytree': 0.9550228527715825, 'reg_alpha': 0.002743713424195251, 'reg_lambda': 2.8422317061974887e-05}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:27,362] Trial 19 finished with value: 0.9692307692307693 and parameters: {'n_estimators': 455, 'learning_rate': 0.039544737909270294, 'max_depth': 5, 'subsample': 0.5008606708361767, 'colsample_bytree': 0.8641685168319182, 'reg_alpha': 0.05277289199834121, 'reg_lambda': 0.04071387847186019}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:27,637] Trial 20 finished with value: 0.9670329670329672 and parameters: {'n_estimators': 291, 'learning_rate': 0.14208978456845128, 'max_depth': 4, 'subsample': 0.713217844623202, 'colsample_bytree': 0.7674465283217102, 'reg_alpha': 8.371649074981618e-07, 'reg_lambda': 1.5486041070383793e-06}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:28,157] Trial 21 finished with value: 0.9714285714285715 and parameters: {'n_estimators': 504, 'learning_rate': 0.05841696308078218, 'max_depth': 7, 'subsample': 0.6244929805022371, 'colsample_bytree': 0.8988215859250489, 'reg_alpha': 0.2488224338972977, 'reg_lambda': 9.600223493357436e-08}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:28,685] Trial 22 finished with value: 0.9736263736263737 and parameters: {'n_estimators': 668, 'learning_rate': 0.09876823852243692, 'max_depth': 8, 'subsample': 0.6354341508742778, 'colsample_bytree': 0.9540232170966318, 'reg_alpha': 0.06354658238288759, 'reg_lambda': 5.364049601451092e-08}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:29,233] Trial 23 finished with value: 0.9692307692307693 and parameters: {'n_estimators': 403, 'learning_rate': 0.02302325247984568, 'max_depth': 3, 'subsample': 0.57419951933413, 'colsample_bytree': 0.9934540930003449, 'reg_alpha': 0.5364394525942745, 'reg_lambda': 7.137815100297149e-05}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:29,705] Trial 24 finished with value: 0.945054945054945 and parameters: {'n_estimators': 671, 'learning_rate': 0.13909363328012278, 'max_depth': 5, 'subsample': 0.6416971049034631, 'colsample_bytree': 0.8592928094089121, 'reg_alpha': 9.05395983446037, 'reg_lambda': 1.9415519299896974e-07}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:30,196] Trial 25 finished with value: 0.9692307692307693 and parameters: {'n_estimators': 395, 'learning_rate': 0.06958497223108433, 'max_depth': 8, 'subsample': 0.7837623916066778, 'colsample_bytree': 0.9136790846374807, 'reg_alpha': 0.0013895070672604371, 'reg_lambda': 2.617931363514147e-06}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:30,626] Trial 26 finished with value: 0.9736263736263737 and parameters: {'n_estimators': 254, 'learning_rate': 0.033055990710551514, 'max_depth': 9, 'subsample': 0.6954552402836126, 'colsample_bytree': 0.9523570682932884, 'reg_alpha': 0.05197757834446376, 'reg_lambda': 8.622402208386679e-08}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:31,062] Trial 27 finished with value: 0.9670329670329672 and parameters: {'n_estimators': 492, 'learning_rate': 0.12845057870137797, 'max_depth': 6, 'subsample': 0.5617004766547415, 'colsample_bytree': 0.7218706979595959, 'reg_alpha': 0.005304500643940831, 'reg_lambda': 3.1977273385912787e-06}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:31,915] Trial 28 finished with value: 0.9648351648351647 and parameters: {'n_estimators': 621, 'learning_rate': 0.01791976087030205, 'max_depth': 4, 'subsample': 0.8915627645196689, 'colsample_bytree': 0.8836429920415797, 'reg_alpha': 6.437811733440601e-05, 'reg_lambda': 3.5150305179269557e-07}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:32,493] Trial 29 finished with value: 0.9670329670329672 and parameters: {'n_estimators': 803, 'learning_rate': 0.2997311384280744, 'max_depth': 9, 'subsample': 0.6133266781057826, 'colsample_bytree': 0.9269855473176845, 'reg_alpha': 0.017932123169564055, 'reg_lambda': 3.4979485057059695e-05}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:33,065] Trial 30 finished with value: 0.964835164835165 and parameters: {'n_estimators': 387, 'learning_rate': 0.04416831114469188, 'max_depth': 7, 'subsample': 0.6562610775399661, 'colsample_bytree': 0.969561426780743, 'reg_alpha': 0.0002166110077055913, 'reg_lambda': 4.5337933506440166e-08}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:33,474] Trial 31 finished with value: 0.9692307692307693 and parameters: {'n_estimators': 284, 'learning_rate': 0.024755886682482207, 'max_depth': 3, 'subsample': 0.6894951332588383, 'colsample_bytree': 0.998913314695503, 'reg_alpha': 0.1422238052949547, 'reg_lambda': 5.34975276932761e-06}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:33,828] Trial 32 finished with value: 0.9736263736263737 and parameters: {'n_estimators': 331, 'learning_rate': 0.06547321335343252, 'max_depth': 3, 'subsample': 0.7166255936208888, 'colsample_bytree': 0.9683935994329672, 'reg_alpha': 0.021134125994473126, 'reg_lambda': 9.312826424399755e-07}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:34,495] Trial 33 finished with value: 0.9714285714285715 and parameters: {'n_estimators': 517, 'learning_rate': 0.016145280122973144, 'max_depth': 3, 'subsample': 0.6803065110530254, 'colsample_bytree': 0.9194622776759258, 'reg_alpha': 0.001257352070942906, 'reg_lambda': 2.0181091294796673e-06}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:34,773] Trial 34 finished with value: 0.9494505494505494 and parameters: {'n_estimators': 120, 'learning_rate': 0.00801145300362689, 'max_depth': 4, 'subsample': 0.5937715218768003, 'colsample_bytree': 0.9795960514115852, 'reg_alpha': 1.0687806007274951, 'reg_lambda': 1.1639250043862114e-05}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:35,326] Trial 35 finished with value: 0.9758241758241759 and parameters: {'n_estimators': 433, 'learning_rate': 0.04227443669253121, 'max_depth': 5, 'subsample': 0.7558907357557408, 'colsample_bytree': 0.6417057332770624, 'reg_alpha': 1.9739706703611136e-05, 'reg_lambda': 0.0012533601337973146}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:35,906] Trial 36 finished with value: 0.9758241758241759 and parameters: {'n_estimators': 462, 'learning_rate': 0.039281265883607926, 'max_depth': 5, 'subsample': 0.7803501109231475, 'colsample_bytree': 0.7059662249969534, 'reg_alpha': 1.7186352149476267e-05, 'reg_lambda': 0.0017551687991324459}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:36,489] Trial 37 finished with value: 0.9692307692307691 and parameters: {'n_estimators': 451, 'learning_rate': 0.037394911518186566, 'max_depth': 5, 'subsample': 0.7843766402081888, 'colsample_bytree': 0.639946667729237, 'reg_alpha': 8.966410032806155e-06, 'reg_lambda': 0.0016486846822962365}. Best is trial 10 with value: 0.9758241758241759.\n",
      "[I 2026-01-06 19:51:37,088] Trial 38 finished with value: 0.9802197802197803 and parameters: {'n_estimators': 582, 'learning_rate': 0.049692410133163445, 'max_depth': 6, 'subsample': 0.7468834723516763, 'colsample_bytree': 0.636119032903889, 'reg_alpha': 6.531260453483897e-06, 'reg_lambda': 0.015919494897547553}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:37,657] Trial 39 finished with value: 0.9736263736263737 and parameters: {'n_estimators': 576, 'learning_rate': 0.05871598167199308, 'max_depth': 6, 'subsample': 0.7403477940824593, 'colsample_bytree': 0.628551903294029, 'reg_alpha': 1.1162219854173963e-06, 'reg_lambda': 0.029148307952757503}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:39,538] Trial 40 finished with value: 0.9538461538461538 and parameters: {'n_estimators': 732, 'learning_rate': 0.0019847304626100983, 'max_depth': 6, 'subsample': 0.9312386649191845, 'colsample_bytree': 0.5416364517661021, 'reg_alpha': 3.516323855597226e-08, 'reg_lambda': 0.006989093653198798}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:40,167] Trial 41 finished with value: 0.9736263736263737 and parameters: {'n_estimators': 620, 'learning_rate': 0.049725570139261106, 'max_depth': 5, 'subsample': 0.7741265258735528, 'colsample_bytree': 0.6902818720500773, 'reg_alpha': 1.606704177895523e-05, 'reg_lambda': 0.18593165205325782}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:40,807] Trial 42 finished with value: 0.9692307692307693 and parameters: {'n_estimators': 386, 'learning_rate': 0.03378775356157395, 'max_depth': 5, 'subsample': 0.8222699786154881, 'colsample_bytree': 0.5054063459271558, 'reg_alpha': 2.9843788938964803e-06, 'reg_lambda': 0.0004859589127254569}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:41,536] Trial 43 finished with value: 0.9736263736263737 and parameters: {'n_estimators': 547, 'learning_rate': 0.021108170614896497, 'max_depth': 4, 'subsample': 0.8062153620685208, 'colsample_bytree': 0.6932384537951886, 'reg_alpha': 1.1973133633903894e-07, 'reg_lambda': 0.008396863998294528}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:42,109] Trial 44 finished with value: 0.9758241758241759 and parameters: {'n_estimators': 482, 'learning_rate': 0.046574718027096576, 'max_depth': 6, 'subsample': 0.7242532329276506, 'colsample_bytree': 0.610339462110217, 'reg_alpha': 3.00366322552355e-05, 'reg_lambda': 0.35954677429650334}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:42,776] Trial 45 finished with value: 0.9736263736263737 and parameters: {'n_estimators': 409, 'learning_rate': 0.030847622759251576, 'max_depth': 5, 'subsample': 0.760467174551062, 'colsample_bytree': 0.6526384329269368, 'reg_alpha': 0.00011904721902780219, 'reg_lambda': 0.00020903709409625555}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:43,494] Trial 46 finished with value: 0.956043956043956 and parameters: {'n_estimators': 284, 'learning_rate': 0.011134489332475591, 'max_depth': 4, 'subsample': 0.8433874084790824, 'colsample_bytree': 0.5908320870934904, 'reg_alpha': 2.454148461795466e-06, 'reg_lambda': 0.0014157015232501024}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:43,885] Trial 47 finished with value: 0.9714285714285715 and parameters: {'n_estimators': 355, 'learning_rate': 0.1022991028410461, 'max_depth': 7, 'subsample': 0.7937827382520843, 'colsample_bytree': 0.6835426460091367, 'reg_alpha': 0.00023925811835820578, 'reg_lambda': 0.006174344213622789}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:44,238] Trial 48 finished with value: 0.9758241758241759 and parameters: {'n_estimators': 177, 'learning_rate': 0.0677666889577889, 'max_depth': 4, 'subsample': 0.7085945570877811, 'colsample_bytree': 0.7949213465261685, 'reg_alpha': 2.156312550024111e-07, 'reg_lambda': 0.0005285546384055424}. Best is trial 38 with value: 0.9802197802197803.\n",
      "[I 2026-01-06 19:51:45,155] Trial 49 finished with value: 0.9714285714285713 and parameters: {'n_estimators': 536, 'learning_rate': 0.014188070935583863, 'max_depth': 5, 'subsample': 0.7348860136904529, 'colsample_bytree': 0.6151145448761904, 'reg_alpha': 3.384036126653408e-05, 'reg_lambda': 0.09291473039489637}. Best is trial 38 with value: 0.9802197802197803.\n",
      "\n",
      "--- Risultati Ottimizzazione ---\n",
      "Miglior Trial (Tentativo #38)\n",
      "Accuratezza Migliore (CV): 0.9802\n",
      "Migliori Iperparametri:\n",
      "  n_estimators: 582\n",
      "  learning_rate: 0.049692410133163445\n",
      "  max_depth: 6\n",
      "  subsample: 0.7468834723516763\n",
      "  colsample_bytree: 0.636119032903889\n",
      "  reg_alpha: 6.531260453483897e-06\n",
      "  reg_lambda: 0.015919494897547553\n",
      "\n",
      "Accuratezza Finale sul Test Set: 0.9649\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- 1. Preparazione Dati ---\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# --- 2. Definizione della \"Objective Function\" ---\n",
    "# Questa è la funzione che Optuna chiamerà centinaia di volte.\n",
    "# Deve restituire UN solo numero: il valore da ottimizzare (es. Accuracy).\n",
    "\n",
    "def objective(trial):\n",
    "    # A. Suggerimento Parametri (Search Space)\n",
    "    # Optuna sceglie i valori in modo intelligente basandosi sulla storia passata\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000), # Intero tra 100 e 1000\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True), # Scala logaritmica\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0), # % feature per albero\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True), # L1 Reg (Lasso)\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True), # L2 Reg (Ridge)\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'gpu',\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        # Early Stopping nel costruttore per versioni recenti (o gestito in fit)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # B. Creazione Modello\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    # C. Validazione Robusta (Cross-Validation)\n",
    "    # Usiamo 5-Fold per essere sicuri che il risultato non sia fortuna\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    # Restituiamo la media dell'accuratezza\n",
    "    return scores.mean()\n",
    "\n",
    "# --- 3. Creazione dello Studio ---\n",
    "print(\"--- Inizio Ottimizzazione Bayesiana ---\")\n",
    "# direction='maximize' perché vogliamo ALTA accuratezza (se fosse RMSE useremmo minimize)\n",
    "study = optuna.create_study(direction='maximize', study_name=\"XGBoost_BreastCancer\")\n",
    "\n",
    "# Lanciamo l'ottimizzazione (es. 50 tentativi)\n",
    "# Optuna mostrerà una progress bar con i risultati in tempo reale\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# --- 4. Risultati ---\n",
    "print(\"\\n--- Risultati Ottimizzazione ---\")\n",
    "print(f\"Miglior Trial (Tentativo #{study.best_trial.number})\")\n",
    "print(f\"Accuratezza Migliore (CV): {study.best_value:.4f}\")\n",
    "print(\"Migliori Iperparametri:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# --- 5. Validazione Finale sul Test Set ---\n",
    "# Ricostruiamo il modello con i parametri vincenti\n",
    "best_params = study.best_params\n",
    "final_model = xgb.XGBClassifier(**best_params, n_jobs=-1, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "final_acc = final_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nAccuratezza Finale sul Test Set: {final_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28f448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-06 20:41:25,782] A new study created in memory with name: XGBoost_BreastCancer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inizio Ottimizzazione Bayesiana ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fdf80f1f724d698f425ae97ea1f3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2026-01-06 20:41:25,794] Trial 0 failed with parameters: {'learning_rate': 0.28754560680450264, 'max_depth': 5, 'subsample': 0.5470549602394306, 'colsample_bytree': 0.9676794290860993, 'reg_alpha': 8.38699124585968, 'reg_lambda': 2.277376003105444e-06} because of the following error: TypeError(\"XGBClassifier.fit() got an unexpected keyword argument 'eval_metric'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\m-rog\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\m-rog\\AppData\\Local\\Temp\\ipykernel_41976\\1584032117.py\", line 43, in objective\n",
      "    model.fit(\n",
      "    ~~~~~~~~~^\n",
      "        X_train,y_train,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        ]\n",
      "        ^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\m-rog\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "TypeError: XGBClassifier.fit() got an unexpected keyword argument 'eval_metric'\n",
      "[W 2026-01-06 20:41:25,796] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "XGBClassifier.fit() got an unexpected keyword argument 'eval_metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 64\u001b[0m\n\u001b[0;32m     60\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost_BreastCancer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Lanciamo l'ottimizzazione (es. 50 tentativi)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Optuna mostrerà una progress bar con i risultati in tempo reale\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# --- 4. Risultati ---\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Risultati Ottimizzazione ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\m-rog\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     _optimize(\n\u001b[0;32m    491\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    492\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    493\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    494\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    495\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    496\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    497\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    498\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    499\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    500\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\m-rog\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 67\u001b[0m         _optimize_sequential(\n\u001b[0;32m     68\u001b[0m             study,\n\u001b[0;32m     69\u001b[0m             func,\n\u001b[0;32m     70\u001b[0m             n_trials,\n\u001b[0;32m     71\u001b[0m             timeout,\n\u001b[0;32m     72\u001b[0m             catch,\n\u001b[0;32m     73\u001b[0m             callbacks,\n\u001b[0;32m     74\u001b[0m             gc_after_trial,\n\u001b[0;32m     75\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     77\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     78\u001b[0m         )\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\m-rog\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\m-rog\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    258\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    261\u001b[0m ):\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[1;32mc:\\Users\\m-rog\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# B. Creazione Modello\u001b[39;00m\n\u001b[0;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m---> 43\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     44\u001b[0m     X_train,y_train,\n\u001b[0;32m     45\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39m[(X_vali, y_vali)],\n\u001b[0;32m     46\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     49\u001b[0m         XGBoostPruningCallback(trial, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_0-logloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m     ]\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     53\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_loss(y_val, y_pred_proba)\n",
      "File \u001b[1;32mc:\\Users\\m-rog\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: XGBClassifier.fit() got an unexpected keyword argument 'eval_metric'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# --- 1. Preparazione Dati ---\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_vali, y_train, y_vali = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- 2. Definizione della \"Objective Function\" ---\n",
    "# Questa è la funzione che Optuna chiamerà centinaia di volte.\n",
    "# Deve restituire UN solo numero: il valore da ottimizzare (es. Accuracy).\n",
    "\n",
    "def objective(trial):\n",
    "    # A. Suggerimento Parametri (Search Space)\n",
    "    # Optuna sceglie i valori in modo intelligente basandosi sulla storia passata\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'n_estimators': 4000,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True), # Scala logaritmica\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0), # % feature per albero\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True), # L1 Reg (Lasso)\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True), # L2 Reg (Ridge)\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'gpu',\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        # Early Stopping nel costruttore per versioni recenti (o gestito in fit)\n",
    "        'earlystopping': 100\n",
    "    }\n",
    "    \n",
    "    # B. Creazione Modello\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train,y_train,\n",
    "        eval_set=[(X_vali, y_vali)],\n",
    "        eval_metric=\"logloss\",\n",
    "        verbose=False,\n",
    "        callbacks=[\n",
    "            XGBoostPruningCallback(trial, \"validation_0-logloss\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    return log_loss(y_val, y_pred_proba)\n",
    "    \n",
    "\n",
    "# --- 3. Creazione dello Studio ---\n",
    "print(\"--- Inizio Ottimizzazione Bayesiana ---\")\n",
    "# direction='maximize' perché vogliamo ALTA accuratezza (se fosse RMSE useremmo minimize)\n",
    "study = optuna.create_study(direction='maximize', study_name=\"XGBoost_BreastCancer\")\n",
    "\n",
    "# Lanciamo l'ottimizzazione (es. 50 tentativi)\n",
    "# Optuna mostrerà una progress bar con i risultati in tempo reale\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# --- 4. Risultati ---\n",
    "print(\"\\n--- Risultati Ottimizzazione ---\")\n",
    "print(f\"Miglior Trial (Tentativo #{study.best_trial.number})\")\n",
    "print(f\"Accuratezza Migliore (CV): {study.best_value:.4f}\")\n",
    "print(\"Migliori Iperparametri:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# --- 5. Validazione Finale sul Test Set ---\n",
    "# Ricostruiamo il modello con i parametri vincenti\n",
    "best_params = study.best_params\n",
    "final_model = xgb.XGBClassifier(**best_params, n_jobs=-1, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "final_acc = final_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nAccuratezza Finale sul Test Set: {final_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
